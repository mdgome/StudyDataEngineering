{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1d64d9-d9b6-4ac6-a88d-e691af77ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4630c056-f9c0-4700-a53a-bb3052076957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ca202d-33df-49e2-a079-da52033a359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/10 10:47:08 WARN Utils: Your hostname, Jungminui-MacBookPro.local resolves to a loopback address: 127.0.0.1; using 172.16.100.122 instead (on interface en0)\n",
      "22/02/10 10:47:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/homebrew/anaconda3/envs/pipeline/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/mdgome/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/mdgome/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ec0f32d9-1a8f-45fa-be9e-9af0a152a9ba;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;2.4.1 in central\n",
      "\tfound org.mongodb#mongo-java-driver;3.10.2 in central\n",
      "\t[3.10.2] org.mongodb#mongo-java-driver;[3.10,3.11)\n",
      ":: resolution report :: resolve 3648ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#mongo-java-driver;3.10.2 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;2.4.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   1   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ec0f32d9-1a8f-45fa-be9e-9af0a152a9ba\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/12ms)\n",
      "22/02/10 10:47:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Configure spark session\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master('local[2]')\\\n",
    "    .appName('quake_etl')\\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:2.4.1')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b1d49eb-e92b-492a-837a-c24b167e9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/mdgome/workspace/spark/3.1.2/LICENSE\"\n",
    "licLines = spark.read.text(path).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e449a422-a88f-4bc1-95d3-7d0b68595785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(licLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a30b465c-548d-402b-9990-a74e5a455171",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/mdgome/workspace/study/StudyDataEngineering/StudyDataEngineering/spark/client-ids.log\"\n",
    "lines = spark.read.text(path).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e28f854b-8e6b-4985-8b5d-cc8343af3772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff03756a-7aad-4bf2-82d7-65db3c98e4ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1341917563.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    .zipWithIndex()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "idsStr = lines.map(lambda x: x.split(\",\" , 1) ).zipWithIndex()\n",
    "idsStr.foreach(println(_))\n",
    "idsStr.first\n",
    "idsStr.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924b52e-771f-4157-bb92-bc6fd08cde74",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueIds = intIds.distinct\n",
    "uniqueIds.collect\n",
    "finalCount  = uniqueIds.count\n",
    "\n",
    "val transactionCount = ids.count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
