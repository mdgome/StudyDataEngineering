{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb226335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting TextToElasticSearchUseSpark_ver0.2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile TextToElasticSearchUseSpark_ver0.2.py\n",
    "\n",
    "import findspark\n",
    "findspark.init() # find spark \n",
    "import datetime as dt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "import findspark\n",
    "import json\n",
    "import pandas as pd \n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "\n",
    "\n",
    "# log data parsing \n",
    "def parsing(row):\n",
    "    row_ = dict()\n",
    "    ts_pattern = re.compile( r\"\\[(\\d+-\\d+-\\d+) ((\\d+:\\d+:\\d+),\\d+)\\]\") \n",
    "\n",
    "    if \"INFO\" in row :\n",
    "        row_[\"Timestamp\"] = ts_pattern.match(row).group(1) +\" \"+ ts_pattern.match(row).group(3)\n",
    "        row_[\"Status\"] = \"INFO\" # Status Parsing \n",
    "        row_[\"Message\"] = row.split(\"INFO - \")[1] # Message Parsing        \n",
    "        \n",
    "    elif \"WARNING\" in row :\n",
    "        row_[\"Timestamp\"] = ts_pattern.match(row).group(1) +\" \"+ ts_pattern.match(row).group(3)\n",
    "        row_[\"Status\"] = \"WARNING\" # Status Parsing \n",
    "        row_[\"Message\"] = row.split(\"WARNING - \")[1] # Message Parsing \n",
    "        \n",
    "        \n",
    "    elif \"ERROR\" in row :\n",
    "        row_[\"Timestamp\"] = ts_pattern.match(row).group(1) +\" \"+ ts_pattern.match(row).group(3)\n",
    "        row_[\"Status\"] = \"ERROR\" # Status Parsing \n",
    "        row_[\"Message\"] = row.split(\"ERROR - \")[1] # Message Parsing   \n",
    "    \n",
    "    return row_    \n",
    "\n",
    "# Elastic Search Store  \n",
    "def bulk_insert(host, port, df, index):\n",
    "    es = Elasticsearch(host = host,port = port)\n",
    "\n",
    "    data = [\n",
    "      {\n",
    "        \"_index\": index,\n",
    "        \"_source\": {\n",
    "            \"datetime\": x[0],\n",
    "            \"log-level\": x[1],\n",
    "            \"message\":x[2]}\n",
    "      }\n",
    "        for x in zip(df['Datetime'],df['Status'],df['Message'])\n",
    "    ]\n",
    "\n",
    "    helpers.bulk(es, data)\n",
    "       \n",
    "\n",
    "    ## 데이터 저장 확인 \n",
    "    \n",
    "    #index = \"airflow_log\"\n",
    "    #body = \"select * from airflow_log\"\n",
    "\n",
    "    #res = es.search(index=index)\n",
    "    #print(res)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "     \n",
    "    spark = SparkSession.builder.master('local[2]').appName('airflow log test').getOrCreate()    \n",
    "    data = spark.read.text(\"error_log_ex.txt\") # change path\n",
    "       \n",
    "    dict_list = []\n",
    "    ts_pattern = re.compile(r'\\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3})]') # timestamp\n",
    "    \n",
    "    for index in range(len(data.collect()) - 1):\n",
    "        row = data.collect()[index]['value']\n",
    "\n",
    "        if ts_pattern.match(row):\n",
    "             dict_list.append(parsing(row))\n",
    "                \n",
    "    df = pd.DataFrame(dict_list)   # pandas DataFrame 변경   \n",
    "    df[\"Datetime\"] = pd.to_datetime(df[\"Timestamp\"],format=\"%Y-%m-%d %M:%H:%S\", errors = 'coerce') \n",
    "\n",
    "    bulk_insert(\"localhost\", \"9200\", df, \"test_ver0.2\")    # es에 데이터 적재 \n",
    "\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585afe47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
